{
    "metadata": {
        "kernelspec": {
            "name": "pyspark3kernel",
            "display_name": "PySpark3"
        },
        "language_info": {
            "name": "pyspark3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "python",
                "version": 3
            },
            "pygments_lexer": "python3"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "<img src=\"https://github.com/Microsoft/sqlworkshops/blob/master/graphics/solutions-microsoft-logo-small.png?raw=true\" alt=\"Microsoft\">\r\n<br>\r\n\r\n# SQL Server 2019 big data cluster Tutorial\r\n## 04 - Using Spark\r\n\r\nIn this tutorial you will learn how to work with Spark Jobs in a SQL Server big data cluster. \r\n\r\n**TODO:** Complete Tutorial ",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Read the product reviews CSV files into a spark data frame, print schema & top rows\r\nresults = spark.read.option(\"inferSchema\", \"true\").csv('/product_review_data').toDF(\"Item_ID\", \"Review\")",
            "metadata": {},
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": "# Save results as parquet file and create hive table\r\nresults.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"Top_Product_Reviews\")",
            "metadata": {},
            "outputs": [],
            "execution_count": 7
        },
        {
            "cell_type": "code",
            "source": "# Execute Spark SQL commands\r\nsqlDF = spark.sql(\"SELECT * FROM Product_Reviews LIMIT 10\")\r\nsqlDF.show()",
            "metadata": {},
            "outputs": [],
            "execution_count": 8
        }
    ]
}